"""
AI Hiring Simulator - Rubric Scorer

This module provides functionality to score candidates based on a predefined
scoring rubric generated by the RubricGenerator. It also includes cultural fit
scoring using the StartupMatcher.
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
from src.matching.startup_matcher import StartupMatcher


class RubricScorer:
    """
    A class for scoring candidates based on a predefined scoring rubric.
    """
    
    def __init__(self, rubric=None, rubric_file=None):
        """
        Initialize the rubric scorer.
        
        Args:
            rubric (dict, optional): Scoring rubric as a dictionary.
            rubric_file (str, optional): Path to a JSON file containing the scoring rubric.
        """
        self.rubric = None
        
        if rubric:
            self.rubric = rubric
        elif rubric_file:
            self.load_rubric(rubric_file)
    
    def load_rubric(self, file_path):
        """
        Load a rubric from a file.
        
        Args:
            file_path (str): Path to the rubric file.
            
        Returns:
            bool: True if successful, False otherwise.
        """
        try:
            # Check if file exists
            if not Path(file_path).exists():
                print(f"Error: Rubric file not found: {file_path}")
                return False
            
            # Load rubric from file
            with open(file_path, 'r', encoding='utf-8') as f:
                self.rubric = json.load(f)
            
            print(f"Rubric loaded from {file_path}")
            return True
            
        except Exception as e:
            print(f"Error loading rubric: {e}")
            return False
    
    def score_candidate(self, candidate):
        """
        Score a candidate based on the scoring rubric.
        
        Args:
            candidate (dict): Candidate data in dictionary format.
            
        Returns:
            dict: Scores for each dimension and overall score.
        """
        if not self.rubric:
            print("Error: No rubric loaded. Load a rubric first.")
            return None
        
        try:
            # Ensure candidate is a dictionary
            if not isinstance(candidate, dict):
                print(f"Error: Candidate data must be a dictionary, got {type(candidate)}")
                return None
            
            # Make sure candidate has a name
            if "name" not in candidate or not candidate["name"]:
                candidate["name"] = "Unknown Candidate"
                
            # Calculate scores for each dimension
            try:
                technical_score = self._score_technical_skills(candidate)
            except Exception as e:
                print(f"Error scoring technical skills for {candidate.get('name', 'candidate')}: {e}")
                technical_score = 0.0
                
            try:
                education_score = self._score_education(candidate)
            except Exception as e:
                print(f"Error scoring education for {candidate.get('name', 'candidate')}: {e}")
                education_score = 0.0
                
            try:
                soft_skills_score = self._score_soft_skills(candidate)
            except Exception as e:
                print(f"Error scoring soft skills for {candidate.get('name', 'candidate')}: {e}")
                soft_skills_score = 0.0
            
            # Calculate overall score (culture fit score will be added separately)
            # Assuming weights: technical 40%, education 20%, soft skills 20%, culture fit 20%
            overall_score = (
                (technical_score * 0.15) +
                (education_score * 0.25) +
                (soft_skills_score * 0.3)
                # Culture fit score (20%) will be added separately
            )
            
            # Return scores
            return {
                "technical_score": technical_score,
                "education_score": education_score,
                "soft_skills_score": soft_skills_score,
                "partial_overall_score": overall_score,  # Without culture fit
                "normalized_overall_score": overall_score * (1.0/0.7)  # Normalized to 0-100 scale (without culture fit)
            }
            
        except Exception as e:
            print(f"Error scoring candidate: {e}")
            return None
    
    def _score_technical_skills(self, candidate):
        """
        Score a candidate's technical skills based on the rubric.
        
        Args:
            candidate (dict): Candidate data.
            
        Returns:
            float: Normalized score for technical skills (0-1).
        """
        # Handle different formats of skills data
        skills = []
        
        # Check if skills is a list
        if "skills" in candidate and isinstance(candidate["skills"], list) and candidate["skills"]:
            skills = [skill.lower() for skill in candidate["skills"]]
            
        # Check if skills is a string (skills_text)
        if "skills_text" in candidate and candidate["skills_text"]:
            if isinstance(candidate["skills_text"], str) and candidate["skills_text"] != "None specified":
                # Add to existing skills list (don't replace if we already have skills)
                skills.extend([skill.strip().lower() for skill in candidate["skills_text"].split(";")])
            elif isinstance(candidate["skills_text"], list):
                # Handle case where skills_text is a list
                skills.extend([str(skill).lower() for skill in candidate["skills_text"]])
        
        if not skills:
            return 0.0
        
        # Get weights and bonus skills from rubric
        weights = {k.lower(): v for k, v in self.rubric["technical_skills"]["weights"].items()}
        bonus_skills = {k.lower(): v for k, v in self.rubric["technical_skills"].get("bonus_skills", {}).items()}
        max_score = self.rubric["technical_skills"]["max_score"]
        
        # Calculate score
        score = 0.0
        matched_skills = set()  # Track matched skills to avoid double counting
        
        # Add score for each skill
        for skill in skills:
            # Check if skill is in weights
            for weight_skill, weight in weights.items():
                if (weight_skill in skill or skill in weight_skill) and weight_skill not in matched_skills:
                    score += weight
                    matched_skills.add(weight_skill)
                    break
            
            # Check if skill is in bonus skills
            for bonus_skill, bonus in bonus_skills.items():
                if (bonus_skill in skill or skill in bonus_skill) and bonus_skill not in matched_skills:
                    score += bonus
                    matched_skills.add(bonus_skill)
                    break
        
        # Extract skills from work experience titles
        if "work_experiences" in candidate and isinstance(candidate["work_experiences"], list):
            for experience in candidate["work_experiences"]:
                if isinstance(experience, dict):
                    role_name = experience.get("roleName", "").lower()
                    
                    # Instead of hardcoded weights, check if role name contains any of the skills in the rubric
                    for weight_skill, weight in weights.items():
                        if weight_skill in role_name and weight_skill not in matched_skills:
                            # Apply a reduced weight for skills inferred from job titles
                            score += weight * 0.5  # Half weight for inferred skills
                            matched_skills.add(weight_skill)
                    
                    # Also check for bonus skills in role names
                    for bonus_skill, bonus in bonus_skills.items():
                        if bonus_skill in role_name and bonus_skill not in matched_skills:
                            score += bonus * 0.5  # Half weight for inferred bonus skills
                            matched_skills.add(bonus_skill)
        
        # Normalize score
        normalized_score = min(score / max_score, 1.0)
        
        return normalized_score
    
    def _score_education(self, candidate):
        """
        Score a candidate's education based on the rubric.
        
        Args:
            candidate (dict): Candidate data.
            
        Returns:
            float: Normalized score for education (0-1).
        """
        # Handle different formats of education data
        degrees = []
        
        # Check for education.degrees format (CSV format)
        if "education.degrees" in candidate and isinstance(candidate["education.degrees"], list):
            degrees = candidate["education.degrees"]
        # Check for nested education dictionary format (JSON format)
        elif "education" in candidate and isinstance(candidate["education"], dict) and "degrees" in candidate["education"]:
            degrees = candidate["education"]["degrees"]
        # Try to extract from education_text if available
        elif "education_text" in candidate and candidate["education_text"] and isinstance(candidate["education_text"], str):
            # This is a simple fallback - we'll just use the text to check for degree levels
            education_text = candidate["education_text"].lower()
            # Create a dummy degree entry with the highest level found
            for level, _ in self.rubric["education"]["degree_levels"].items():
                if level.lower() in education_text:
                    degrees = [{"degree": level}]
                    break
        
        if not degrees:
            return 0.0
        
        # Get education scoring criteria from rubric
        degree_levels = self.rubric["education"]["degree_levels"]
        field_relevance = self.rubric["education"]["field_relevance"]
        gpa_scores = self.rubric["education"]["gpa_scores"]
        school_quality = self.rubric["education"]["school_quality"]
        recency_factor = self.rubric["education"]["recency_factor"]
        max_score = self.rubric["education"]["max_score"]
        
        # Calculate score
        score = 0.0
        current_year = datetime.now().year
        
        for degree in degrees:
            if not isinstance(degree, dict):
                continue
                
            degree_score = 0.0
            
            # Score for degree level
            degree_level = degree.get("degree", "")
            for level, weight in degree_levels.items():
                if level.lower() in degree_level.lower():
                    degree_score += weight
                    break
            
            # Score for field relevance
            subject = degree.get("subject", "").lower()
            field_score = 0.0
            for field, relevance in field_relevance.items():
                if field.lower() in subject:
                    field_score = relevance
                    break
            
            if field_score == 0.0 and "Other" in field_relevance:
                field_score = field_relevance["Other"]
            
            # Add field relevance score (not multiply)
            degree_score += field_score
            
            # Score for GPA
            gpa = degree.get("gpa", "")
            gpa_score = 0.0
            
            # Handle numeric GPA values
            if isinstance(gpa, (int, float)) or (isinstance(gpa, str) and gpa.replace('.', '', 1).isdigit()):
                try:
                    gpa_value = float(gpa)
                    # Match to the appropriate GPA range in the rubric
                    if gpa_value >= 4.0:
                        gpa_score = gpa_scores.get("GPA 4.0", 0)
                    elif gpa_value >= 3.5:
                        gpa_score = gpa_scores.get("GPA 3.5-3.9", 0)
                    elif gpa_value >= 3.0:
                        gpa_score = gpa_scores.get("GPA 3.0-3.4", 0)
                    elif gpa_value >= 2.5:
                        gpa_score = gpa_scores.get("GPA 2.5-2.9", 0)
                    else:
                        gpa_score = gpa_scores.get("GPA < 2.5", 0)
                except (ValueError, TypeError):
                    pass
            else:
                # Try to match string GPA descriptions
                for gpa_range, score_value in gpa_scores.items():
                    if gpa_range.lower() in str(gpa).lower():
                        gpa_score = score_value
                        break
            
            degree_score += gpa_score
            
            # Score for school quality
            is_top25 = degree.get("isTop25", False)
            is_top50 = degree.get("isTop50", False)
            
            if is_top25:
                degree_score += school_quality.get("top25_bonus", 0)
            elif is_top50:
                degree_score += school_quality.get("top50_bonus", 0)
            
            # Check school tier
            school_name = degree.get("school", "").lower()
            school_tier_scores = school_quality.get("school_tier_scores", {})
            
            # Try to match school name to a tier
            for tier, tier_score in school_tier_scores.items():
                # Check if the tier name appears in the school name
                # This is a simple heuristic and could be improved
                if tier.lower() in school_name:
                    degree_score += tier_score
                    break
            
            # Apply recency factor
            recency_value = 0
            end_date = degree.get("endDate", "")
            if end_date and str(end_date).isdigit():
                years_since_graduation = current_year - int(end_date)
                if years_since_graduation <= 5:
                    recency_value = recency_factor.get("within_5_years", 10)
                elif years_since_graduation <= 10:
                    recency_value = recency_factor.get("within_10_years", 7)
                else:
                    recency_value = recency_factor.get("older", 5)
            else:
                # Default to older if no date is provided
                recency_value = recency_factor.get("older", 5)
            
            # Add recency value to the degree score
            degree_score += recency_value
            
            # Add degree score to total score
            score += degree_score
        
        # Normalize score
        normalized_score = min(score / max_score, 1.0)
        
        return normalized_score
    
    def _score_soft_skills(self, candidate):
        """
        Score a candidate's soft skills based on the rubric.
        
        Args:
            candidate (dict): Candidate data.
            
        Returns:
            float: Normalized score for soft skills (0-1).
        """
        print(f"\n=== Scoring soft skills for {candidate.get('name', 'Unknown Candidate')} ===")
        
        # Print rubric information for debugging
        print(f"Soft Skills Rubric:")
        if 'soft_skills' in self.rubric:
            print(f"  Leadership terms: {self.rubric['soft_skills'].get('leadership_terms', {})}")
            print(f"  Max score: {self.rubric['soft_skills'].get('max_score', 0)}")
        else:
            print("  ERROR: 'soft_skills' section not found in rubric!")
            return 0.0
        
        # Get the work experience text instead of structured work experiences
        work_experience_text = candidate.get("work_experience_text", "")
        print(f"Work experience text length: {len(work_experience_text)}")
        
        if not work_experience_text:
            print("No work experience text found, returning 0.0")
            return 0.0
        
        # Convert to lowercase for case-insensitive matching
        work_experience_text = work_experience_text.lower()
        
        # Get soft skills scoring criteria from rubric
        leadership_terms = self.rubric["soft_skills"]["leadership_terms"]
        max_score = self.rubric["soft_skills"]["max_score"]
        
        # Calculate score
        score = 0.0
        found_matches = False  # Track if we found any matches
        
        print("\nAnalyzing work experience text:")
        print(f"Work experience text (excerpt): {work_experience_text[:200]}...")
        
        # Score for leadership terms - allow double counting
        for term, weight in leadership_terms.items():
            term_lower = term.lower()
            # Count how many times the term appears in the text
            count = work_experience_text.count(term_lower)
            if count > 0:
                # Add the weight for each occurrence
                points = weight * count
                score += points
                found_matches = True
                print(f"  MATCH: Leadership term '{term}' found {count} times, adding {points} points ({weight} × {count})")
        
        if not found_matches:
            print("  No leadership terms matched in the work experience text")
        
        # Normalize score
        normalized_score = min(score / max_score, 1.0)
        print(f"Final soft skills score: {score} / {max_score} = {normalized_score:.4f} (normalized)")
        
        return normalized_score
    
    def score_candidates(self, candidates):
        """
        Score multiple candidates based on the scoring rubric.
        
        Args:
            candidates (list): List of candidate data dictionaries.
            
        Returns:
            list: List of dictionaries with candidate data and scores.
        """
        if not self.rubric:
            print("Error: No rubric loaded. Load a rubric first.")
            return None
        
        try:
            scored_candidates = []
            
            for candidate in candidates:
                scores = self.score_candidate(candidate)
                
                if scores:
                    # Add scores to candidate data
                    candidate_with_scores = candidate.copy()
                    candidate_with_scores.update(scores)
                    scored_candidates.append(candidate_with_scores)
            
            # Apply Z-score normalization to subscores only (not overall score) if we have multiple candidates
            if len(scored_candidates) >= 2:
                # Extract subscores
                technical_scores = [candidate["technical_score"] * 100 for candidate in scored_candidates]
                education_scores = [candidate["education_score"] * 100 for candidate in scored_candidates]
                soft_skills_scores = [candidate["soft_skills_score"] * 100 for candidate in scored_candidates]
                
                # Normalize subscores to 60-99 range
                normalized_technical = self.normalize_scores_z_score(technical_scores, 60, 99)
                normalized_education = self.normalize_scores_z_score(education_scores, 60, 99)
                normalized_soft_skills = self.normalize_scores_z_score(soft_skills_scores, 60, 99)
                
                # Update candidates with Z-score normalized subscores only
                for i, candidate in enumerate(scored_candidates):
                    candidate["z_normalized_technical"] = normalized_technical[i]
                    candidate["z_normalized_education"] = normalized_education[i]
                    candidate["z_normalized_soft_skills"] = normalized_soft_skills[i]
            
            return scored_candidates
            
        except Exception as e:
            print(f"Error scoring candidates: {e}")
            return None
    
    def calculate_cultural_fit(self, candidates_df, startup_description):
        """
        Calculate cultural fit scores for candidates using StartupMatcher.
        
        Args:
            candidates_df (pandas.DataFrame): DataFrame containing candidate data.
            startup_description (str): Description of the startup for cultural fit scoring.
            
        Returns:
            pandas.DataFrame: DataFrame with culture fit scores.
        """
        try:
            # Print the number of candidates before processing
            print(f"Calculating cultural fit for {len(candidates_df)} candidates")
            
            # Create a StartupMatcher instance
            matcher = StartupMatcher()
            
            # Load pre-existing embeddings from the npy file
            embeddings_path = Path('data/processed/candidate_embeddings.npy')
            if not embeddings_path.exists():
                print(f"Warning: Embeddings file not found at {embeddings_path}")
                # Try alternative location
                embeddings_path = Path('processed_data/candidate_embeddings.npy')
                if not embeddings_path.exists():
                    print(f"Error: Embeddings file not found at {embeddings_path} either")
                    return None
            
            # Load the embeddings directly
            print(f"Loading pre-existing embeddings from {embeddings_path}")
            matcher.embedding_gen.load_embeddings(embeddings_path)
            
            # Directly embed the startup description
            matcher.embed_startup(startup_description)
            
            # Calculate culture fit scores directly
            matcher.calculate_culture_fit_scores()
            
            # Create a simple DataFrame with just the culture fit scores
            # Make sure we have exactly the same number of scores as candidates
            culture_fit_df = pd.DataFrame({
                'culture_fit_score': matcher.culture_fit_scores[:len(candidates_df)]
            })
            
            print(f"Created culture fit scores for {len(culture_fit_df)} candidates")
            
            return culture_fit_df
            
        except Exception as e:
            print(f"Error calculating cultural fit: {e}")
            return None
    

    def update_scores_with_cultural_fit(self, scored_df, culture_fit_df):
        """
        Update candidate scores with cultural fit scores and recalculate overall score.
        
        Args:
            scored_df (pandas.DataFrame): DataFrame with candidate scores (from score_candidates_df).
            culture_fit_df (pandas.DataFrame): DataFrame with culture fit scores (from StartupMatcher).
            
        Returns:
            pandas.DataFrame: DataFrame with updated scores including cultural fit.
        """
        try:
            if 'culture_fit_score' not in culture_fit_df.columns:
                print("Error: Culture fit scores not found in the provided DataFrame.")
                return scored_df
            
            # Simple approach: directly assign culture fit scores if DataFrames have the same length
            if len(scored_df) == len(culture_fit_df):
                print(f"Adding culture fit scores to {len(scored_df)} candidates")
                # Direct assignment - no merge needed
                scored_df['culture_fit_score'] = culture_fit_df['culture_fit_score'].values
            else:
                print(f"Warning: Scored candidates ({len(scored_df)}) and culture fit scores ({len(culture_fit_df)}) have different lengths")
                # If different lengths, use a default score
                scored_df['culture_fit_score'] = 0.5
            
            # Fill any missing culture fit scores with a default value (0.5)
            scored_df['culture_fit_score'] = scored_df['culture_fit_score'].fillna(0.5)
            
            # Recalculate overall score with culture fit (20% weight)
            # The partial_overall_score already has 80% of the total (technical 40%, education 20%, soft skills 20%)
            scored_df['normalized_overall_score'] = scored_df['partial_overall_score'] + (scored_df['culture_fit_score'] * 0.3)
            
            # Apply Z-score normalization to get scores in the 60-99 range
            if len(scored_df) >= 2:
                # Convert to list for normalization
                overall_scores = scored_df['normalized_overall_score'].values * 100
                technical_scores = scored_df['technical_score'].values * 100
                education_scores = scored_df['education_score'].values * 100
                soft_skills_scores = scored_df['soft_skills_score'].values * 100
                culture_fit_scores = scored_df['culture_fit_score'].values * 100
                
                # Print soft skills scores for debugging
                print(f"Soft skills scores before normalization: {soft_skills_scores}")
                
                # Normalize scores using Z-score normalization
                normalized_overall = self.normalize_scores_z_score(overall_scores, 60, 99)
                normalized_technical = self.normalize_scores_z_score(technical_scores, 60, 99)
                normalized_education = self.normalize_scores_z_score(education_scores, 60, 99)
                normalized_soft_skills = self.normalize_scores_z_score(soft_skills_scores, 60, 99)
                normalized_culture_fit = self.normalize_scores_z_score(culture_fit_scores, 60, 99)
                
                # Debug information about normalized scores
                print(f"Normalized overall scores (sample): {normalized_overall[:5] if len(normalized_overall) > 5 else normalized_overall}")
                # Add the Z-score normalized scores to the DataFrame
                scored_df['z_normalized_score'] = normalized_overall
                scored_df['z_normalized_technical'] = normalized_technical
                scored_df['z_normalized_education'] = normalized_education
                scored_df['z_normalized_soft_skills'] = normalized_soft_skills
                scored_df['z_normalized_culture_fit'] = normalized_culture_fit
            else:
                # If only one candidate, assign middle of range (79.5)
                scored_df['z_normalized_score'] = 79.5
                scored_df['z_normalized_technical'] = 79.5
                scored_df['z_normalized_education'] = 79.5
                scored_df['z_normalized_soft_skills'] = 79.5
                scored_df['z_normalized_culture_fit'] = 79.5
            
            print(f"Scores updated with cultural fit for {len(scored_df)} candidates")
            
            return scored_df
            
        except Exception as e:
            print(f"Error updating scores with cultural fit: {e}")
            return scored_df
    
    def score_candidates_df(self, candidates_df, startup_description=None):
        """
        Score candidates from a pandas DataFrame.
        
        Args:
            candidates_df (pandas.DataFrame): DataFrame containing candidate data.
            startup_description (str, optional): Description of the startup for cultural fit scoring.
            
        Returns:
            pandas.DataFrame: DataFrame with added score columns.
        """
        if not self.rubric:
            print("Error: No rubric loaded. Load a rubric first.")
            return None
        
        try:
            # Convert DataFrame to list of dictionaries
            candidates = candidates_df.to_dict('records')
            
            # Score candidates
            scored_candidates = self.score_candidates(candidates)
            
            if scored_candidates:
                # Convert back to DataFrame
                scored_df = pd.DataFrame(scored_candidates)
                
                # Calculate and update with cultural fit if startup description is provided
                if startup_description:
                    culture_fit_df = self.calculate_cultural_fit(candidates_df, startup_description)
                    if culture_fit_df is not None:
                        scored_df = self.update_scores_with_cultural_fit(scored_df, culture_fit_df)
                
                return scored_df
            else:
                return None
            
        except Exception as e:
            print(f"Error scoring candidates from DataFrame: {e}")
            return None
    
    def normalize_scores_z_score(self, scores, min_score=40, max_score=99):
        """
        Normalize scores using Z-score normalization and scale to a specified range.
        
        Args:
            scores (list or numpy.ndarray): List or array of numerical scores to normalize.
            min_score (int): Minimum score in the output range.
            max_score (int): Maximum score in the output range.
            
        Returns:
            list: Normalized scores in the specified range.
        """
        import numpy as np
        
        # Convert scores to numpy array for easier handling
        scores_array = np.array(scores)
        
        # Check if we have enough scores for meaningful normalization
        if scores_array.size < 2:
            return scores_array.tolist()
            
        # Calculate mean and standard deviation
        mean = np.mean(scores_array)
        std = np.std(scores_array)
        
        # Avoid division by zero if all scores are the same
        if std < 0.0001:  # Using a small threshold instead of exact zero
            return np.full(scores_array.shape, min_score + (max_score - min_score) / 2).tolist()
        
        # Calculate Z-scores: (x - mean) / std
        z_scores = (scores_array - mean) / std
        
        # Clip to an asymmetric range [-3, 4] instead of [-3, 3]
        # This makes high scores more difficult to achieve
        z_clipped = np.clip(z_scores, -3, 4)
        
        # Map from [-3, 4] to [0, 1] range
        scaled = (z_clipped + 3) / 7  # Dividing by 7 instead of 6
        
        # Map to [min_score, max_score] range
        normalized_scores = min_score + scaled * (max_score - min_score)
        
        # Apply a simple penalty to top scores
        # This creates a "ceiling effect" making 99s much rarer
        normalized_scores = np.array([
            score - (0.5 * max(0, score - 95)) if score > 95 else score 
            for score in normalized_scores
        ])
        
        # Round and return as list
        return np.round(normalized_scores).astype(int).tolist()


if __name__ == "__main__":
    import argparse
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Score candidates based on a scoring rubric.')
    parser.add_argument('--rubric', type=str, required=True,
                        help='Path to the scoring rubric JSON file')
    parser.add_argument('--candidates', type=str, required=True,
                        help='Path to the candidates JSON file')
    parser.add_argument('--output', type=str, default='scored_candidates.json',
                        help='Path to save the scored candidates')
    
    args = parser.parse_args()
    
    # Create rubric scorer
    scorer = RubricScorer(rubric_file=args.rubric)
    
    # Load candidates
    with open(args.candidates, 'r', encoding='utf-8') as f:
        candidates = json.load(f)
    
    # Score candidates
    scored_candidates = scorer.score_candidates(candidates)
    
    if scored_candidates:
        # Save scored candidates
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(scored_candidates, f, indent=2)
        
        print(f"Scored candidates saved to {args.output}")
    else:
        print("Failed to score candidates.")
